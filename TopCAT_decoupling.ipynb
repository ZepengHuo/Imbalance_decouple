{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, datetime\n",
    "import torch\n",
    "import random \n",
    "import numpy as np \n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "from itertools import cycle\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score, brier_score_loss\n",
    "#from pytorch_lightning.metrics.functional.classification import f1_score, auroc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from resnetv2 import PreActResNet18 as ResNet18  \n",
    "from utils import Labeled_dataset\n",
    "from MLP_base import Net as mlp\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from resblock_searched import Appended_Model\n",
    "\n",
    "from temperature_scaling import ModelWithTemperature\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Cifar10_100 Training')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='initial learning rate')\n",
    "parser.add_argument('--data_dir', help='The directory for data', default='trans_data', type=str)\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float, help='weight decay')\n",
    "parser.add_argument('--epochs', default=100, type=int, help='number of total epochs to run')\n",
    "parser.add_argument('--print_freq', default=50, type=int, help='print frequency')\n",
    "parser.add_argument('--decreasing_lr', default='60,80', help='decreasing strategy')\n",
    "parser.add_argument('--save_dir', help='The directory used to save the trained models', default='cifar10_cil', type=str)\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n",
    "parser.add_argument('--load_model', default=False, type=eval, choices=[True, False], help='load last checkpoint to continue training')\n",
    "parser.add_argument('--drop_r', default=0.3, type=float, help='drop out rate')\n",
    "parser.add_argument('--out_size', default=10, type=int, help='total possible labels (binary is 1)')\n",
    "parser.add_argument('--lr_Plateau_factor', default=0.1, type=float, help='torch.optim.lr_scheduler.ReduceLROnPlateau: Factor by which the learning rate will be reduced')\n",
    "parser.add_argument('--lr_Plateau_patience', default=10, type=int, help='torch.optim.lr_scheduler.ReduceLROnPlateau: Number of epochs with no improvement after which learning rate will be reduced')\n",
    "\n",
    "\n",
    "best_prec1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_cols = [\n",
    "    'death', 'cvd_death', 'time_death', 'anyhosp', 'time_anyhosp',\n",
    "    'hfhosp', 'time_hfhosp', 'abortedca', 'time_abortedca', 'mi',\n",
    "    'time_mi', 'stroke', 'time_stroke', 'primary_ep', 'time_primary_ep'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cat_cols = [\n",
    "    'GLUCOSE_FAST', 'GLUCOSE_RAND', 'CO2_mmolL', 'GLUCOSE_mgdL','WBC_kuL',\n",
    "    'HCT_p', 'HB_gdL', 'PLT_kuL', 'ALP_UL', 'TBILI_mgdL', 'ALB_gdL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_cols = [\n",
    "    'BNP_VAL', 'age_entry', 'EF', 'visit_dt1_hf', 'chfdc_dt3', 'mi_dt3',\n",
    "    'stroke_dt3', 'cabg_dt3', 'pci_dt3', 'DM_AGE_YR', 'DM_DUR_YR', 'cigs',\n",
    "    'SMOKE_YRS', 'QUIT_YRS', 'HEAVY_MIN', 'HEAVY_WK', 'MED_WK', 'MED_MIN',\n",
    "    'LIGHT_WK', 'LIGHT_MIN', 'metsperweek', 'cooking_salt_score', 'height',\n",
    "    'weight', 'waistc', 'HR', 'SBP', 'DBP', 'CR_mgdl', 'gfr', 'labs_dt1',\n",
    "    'NA_mmolL', 'K_mmolL', 'CL_mmolL', 'BUN_mgdL', 'ALT_UL', 'AST_UL',\n",
    "    'urine_val_mgg', 'QRS_DUR', 'CR_mgdL', 'BMI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "priep = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/primary_ep_set.csv', index_col=0)\n",
    "death = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/death_set.csv'     , index_col=0)\n",
    "hfhos = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/hfhosp_set.csv'    , index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "\n",
    "if mode == 1:\n",
    "    outcome = 'primary_ep'\n",
    "    outcome_time = 'time_primary_ep'\n",
    "    df = priep.copy()\n",
    "elif mode == 2:\n",
    "    outcome = 'death'\n",
    "    outcome_time = 'time_death'\n",
    "    df = death.copy()\n",
    "elif mode == 3:\n",
    "    outcome = 'hfhosp'\n",
    "    outcome_time = 'time_hfhosp'\n",
    "    df = hfhos.copy()\n",
    "\n",
    "labels = df[outcome].copy()\n",
    "complete_labels = labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, if_main=False):\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    aucrocs = AverageMeter()\n",
    "    aucprs = AverageMeter()\n",
    "    f1_scores = AverageMeter()\n",
    "    \n",
    "    # for confusion matrix\n",
    "    #pred_ls = torch.empty(len(val_loader.dataset))\n",
    "    #true_ls = torch.empty(len(val_loader.dataset))\n",
    "    \n",
    "    model = model.eval()\n",
    "    \n",
    "    y_pred_ls = []\n",
    "    y_true_ls = []\n",
    "    \n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        #true_ls[val_loader.batch_size * i, val_loader.batch_size * (i+1)] = target\n",
    "        \n",
    "        \n",
    "        input = input.cuda()\n",
    "        target = target.long().cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            \n",
    "            if args.out_size == 1:\n",
    "                output = torch.sigmoid(output)\n",
    "            \n",
    "            #loss = criterion(output, target)\n",
    "            loss = criterion_ExpandTarget(output, target, criterion)\n",
    "            \n",
    "        \n",
    "        output = output.float()\n",
    "        #pred_ls[val_loader.batch_size * i, val_loader.batch_size * (i+1)] = np.argmax(output, axis=1)\n",
    "        y_pred_ls.append(output.cpu().numpy()[:,1])\n",
    "        y_true_ls.append(target.cpu().numpy())\n",
    "        \n",
    "        loss = loss.float()    \n",
    "        \n",
    "          \n",
    "        #aurocsore = auroc(output[:, 1].data, target)  \n",
    "        #aurocsore = roc_auc_score(target, output[:, 1])\n",
    "        aucprscore = aucpr(output.data.cpu(), target.cpu())  \n",
    "        #print(aurocsore, aucprscore)\n",
    "        #f1score = f1_score(output.data, target, pos_label=1)\n",
    "        bss = brierskillscore(output.data.cpu()[:,1], target.cpu())\n",
    "        \n",
    "        #aucrocs.update(aurocsore.item(), input.size(0))\n",
    "        #temporary workaround, delete after use\n",
    "        aucrocs.update(bss, input.size(0))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #aucprs.update(aucprscore.item(), input.size(0))\n",
    "        #f1_scores.update(f1score.item(), input.size(0))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        '''   \n",
    "        if i % args.print_freq == 0:\n",
    "            print('Test: [{0}/{1}]  '\n",
    "                  'Loss {loss.avg:.4f}  '\n",
    "                  'aucroc {aucrocs.avg:.3f}  '\n",
    "                  #'aucpr {aucprs.avg:.3f}  '\n",
    "                  #'f1 {f1_scores.avg:.3f}'\n",
    "                  .format(i, len(val_loader), loss=losses, \n",
    "                          aucrocs=aucrocs, \n",
    "                          #aucprs=aucprs, \n",
    "                          #f1_scores=f1_scores\n",
    "                         ))\n",
    "          \n",
    "    \n",
    "    print('aucroc {aucrocs.avg:.3f}  '\n",
    "          #'aucpr {aucprs.avg:.3f}  '\n",
    "          #'f1 {f1_scores.avg:.3f}'\n",
    "          .format(aucrocs=aucrocs, \n",
    "                  #aucprs=aucprs, f1_scores=f1_scores\n",
    "                 ))'''\n",
    "    \n",
    "    \n",
    "    #print_confusion_matrix(pred_ls, true_ls, labels=[0, 1])\n",
    "    y_pred_ls = np.array(y_pred_ls)\n",
    "    y_true_ls = np.array(y_true_ls)\n",
    "    bss = brierskillscore(y_pred_ls, y_true_ls)\n",
    "    #return statistics.mean(f1_score_ls), statistics.mean(accuracy_ls), statistics.mean(auroc_score_ls), statistics.mean(auc_pr_ls)\n",
    "    #return losses.avg, aucrocs.avg\n",
    "    return losses.avg, bss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline training: not decoupling\n",
    "\n",
    "def training(rand_loader, new_balance_loader, old_balance_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    coef_old = int(args.batch_size/2)/64\n",
    "    coef_new = int(args.batch_size/2)/64\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    new_balance = iter(new_balance_loader)\n",
    "    old_balance = iter(old_balance_loader)\n",
    "\n",
    "    for i, (input, target) in enumerate(rand_loader):\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            bal_new_img, bal_new_target = next(new_balance)\n",
    "        except StopIteration:\n",
    "            new_balance = iter(new_balance_loader)\n",
    "            bal_new_img, bal_new_target = next(new_balance)\n",
    "\n",
    "        try:\n",
    "            bal_old_img, bal_old_target = next(old_balance)\n",
    "        except StopIteration:\n",
    "            old_balance = iter(old_balance_loader)\n",
    "            bal_old_img, bal_old_target = next(old_balance)\n",
    "        \n",
    "\n",
    "        bal_new_img = bal_new_img.cuda()\n",
    "        bal_old_img = bal_old_img.cuda()\n",
    "        '''\n",
    "        input = input.cuda()\n",
    "\n",
    "        '''\n",
    "        bal_new_target = bal_new_target.long().cuda()new_balance_loader\n",
    "        bal_old_target = bal_old_target.long().cuda()\n",
    "        '''\n",
    "        target = target.long().cuda()\n",
    "\n",
    "        # random input\n",
    "        output_gt = model(input, main_fc=False)\n",
    "        loss_rand = criterion(output_gt, target)\n",
    "        \n",
    "        '''\n",
    "        # balance inputs\n",
    "        output_bal_new = model(bal_new_img, main_fc=True)\n",
    "        output_bal_old = model(bal_old_img, main_fc=True)\n",
    "        loss_balance = criterion(output_bal_new, bal_new_target)*coef_new + criterion(output_bal_old, bal_old_target)*coef_old\n",
    "        '''\n",
    "        \n",
    "        if tensor_allNaN(output_gt):\n",
    "            print('output_gt')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(loss_rand):\n",
    "            print('loss_rand')\n",
    "            sys.exit()\n",
    "        '''\n",
    "        if tensor_allNaN(output_bal_new):\n",
    "            print('output_bal_new')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(output_bal_old):\n",
    "            print('output_bal_old')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(loss_balance):\n",
    "            print('loss_balance')  \n",
    "            sys.exit()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #loss = (loss_balance + loss_rand)*0.5\n",
    "        loss = loss_rand\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output_gt.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = auroc(output.data, target)   \n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'auroc {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(rand_loader), loss=losses, top1=top1))\n",
    "            \n",
    "\n",
    "    print('train_accuracy {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(rand_loader, new_balance_loader, old_balance_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    losses_rand = AverageMeter()\n",
    "    top1_rand = AverageMeter()\n",
    "    \n",
    "    losses_bal = AverageMeter()\n",
    "    top1_bal = AverageMeter()\n",
    "    \n",
    "\n",
    "    coef_old = 0.5\n",
    "    coef_new = 0.5\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    new_balance = iter(new_balance_loader)\n",
    "    old_balance = iter(old_balance_loader)\n",
    "\n",
    "    for i, (input, target) in enumerate(rand_loader):\n",
    "\n",
    "        \n",
    "        try:\n",
    "            bal_new_img, bal_new_target = next(new_balance)\n",
    "        except StopIteration:\n",
    "            new_balance = iter(new_balance_loader)\n",
    "            bal_new_img, bal_new_target = next(new_balance)\n",
    "\n",
    "        try:\n",
    "            bal_old_img, bal_old_target = next(old_balance)\n",
    "        except StopIteration:\n",
    "            old_balance = iter(old_balance_loader)\n",
    "            bal_old_img, bal_old_target = next(old_balance)\n",
    "        \n",
    "\n",
    "        bal_new_img = bal_new_img.cuda()\n",
    "        bal_old_img = bal_old_img.cuda()\n",
    "        \n",
    "        input = input.cuda()\n",
    "\n",
    "        \n",
    "        bal_new_target = bal_new_target.long().cuda()\n",
    "        bal_old_target = bal_old_target.long().cuda()\n",
    "        \n",
    "        target = target.long().cuda()\n",
    "\n",
    "        # random input\n",
    "        output_gt = model(input, main_fc=False)\n",
    "        #loss_rand = criterion(output_gt, target)\n",
    "        loss_rand = criterion_ExpandTarget(output_gt, target, criterion)\n",
    "\n",
    "        \n",
    "        # balance inputs\n",
    "        output_bal_new = model(bal_new_img, main_fc=True)\n",
    "        output_bal_old = model(bal_old_img, main_fc=True)\n",
    "        \n",
    "        \n",
    "        #loss_new = criterion(output_bal_new, bal_new_target.unsqueeze(1).type_as(output_bal_new))*coef_new\n",
    "        loss_new = criterion_ExpandTarget(output_bal_new, bal_new_target, criterion)*coef_new\n",
    "        \n",
    "        \n",
    "        #loss_old = criterion(output_bal_old, bal_old_target.unsqueeze(1).type_as(output_bal_old))*coef_old\n",
    "        loss_old = criterion_ExpandTarget(output_bal_old, bal_old_target, criterion)*coef_old\n",
    "        \n",
    "        loss_balance = loss_new + loss_old\n",
    "        \n",
    "        # check if any output is NaN\n",
    "        if tensor_allNaN(output_gt):\n",
    "            print('output_gt')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(loss_rand):\n",
    "            print('loss_rand')\n",
    "            sys.exit()\n",
    "        \n",
    "        if tensor_allNaN(output_bal_new):\n",
    "            print('output_bal_new')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(output_bal_old):\n",
    "            print('output_bal_old')\n",
    "            sys.exit()\n",
    "        if tensor_allNaN(loss_balance):\n",
    "            print('loss_balance')  \n",
    "            sys.exit()\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = (loss_balance + loss_rand)*0.5\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output_gt.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss, for balanced classifier\n",
    "        output_cpu = output.cpu().detach().numpy()\n",
    "        output_bal_new_cpu = output_bal_new.cpu().detach().numpy()\n",
    "        output_bal_old_cpu = output_bal_old.cpu().detach().numpy()\n",
    "        output_bal_cpu = np.concatenate((output_bal_new_cpu, output_bal_old_cpu))\n",
    "        \n",
    "        target_cpu = target.cpu().detach().numpy()\n",
    "        bal_new_target_cpu = bal_new_target.cpu().detach().numpy()\n",
    "        bal_old_target_cpu = bal_old_target.cpu().detach().numpy()\n",
    "        bal_target_cpu = np.concatenate((bal_new_target_cpu, bal_old_target_cpu))\n",
    "        \n",
    "        #prec1 = auroc(output.data, target)   \n",
    "        auroc_rand = roc_auc_score(target_cpu, output_cpu[:, 1])\n",
    "        auroc_bal = roc_auc_score(bal_target_cpu, output_bal_cpu[:, 1])\n",
    "        \n",
    "        \n",
    "        losses_rand.update(loss_rand.item(), input.size(0))        \n",
    "        losses_bal.update(loss_balance.item(), output_bal_cpu.shape[0])\n",
    "        top1_rand.update(auroc_rand.item(), input.size(0))\n",
    "        top1_bal.update(auroc_bal.item(), output_bal_cpu.shape[0])\n",
    "\n",
    "        '''\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'auroc {top1_rand.val:.3f} ({top1_rand.avg:.3f})'.format(\n",
    "                      epoch, i, len(rand_loader), loss=losses_rand, top1_rand=top1_rand))\n",
    "            \n",
    "\n",
    "    print('train_accuracy {top1_rand.avg:.3f}'.format(top1_rand=top1_rand))'''\n",
    "\n",
    "    return losses_rand.avg, losses_bal.avg, top1_bal.avg, top1_rand.avg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[0.1, 0.9], [0.8, 0.2], [0.7, 0.3]])\n",
    "# b = torch.tensor([1, 1, 0])\n",
    "# aucpr(a, b)\n",
    "# tensor(0.8333, dtype=torch.float64)\n",
    "\n",
    "def aucpr(pred, true, average='macro'):\n",
    "    pred = pred.numpy()[:, 1]\n",
    "    true = true.numpy()\n",
    "    aucprscore = average_precision_score(true, pred, average=average)\n",
    "    aucprscore = torch.tensor(aucprscore)\n",
    "    \n",
    "    return aucprscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brierskillscore(y_pred, y_true):\n",
    "    #print(y_pred.shape, y_true.shape)\n",
    "    cls_num_list = np.unique(y_true, return_counts=True)[1]\n",
    "    ratio = float(cls_num_list[1]) / np.sum(cls_num_list)\n",
    "    y_true, y_pred = y_true.reshape(1,-1).squeeze(), y_pred.reshape(1,-1).squeeze()\n",
    "    y_pred_sig = 1/(1 + np.exp(-y_pred))\n",
    "    predictions_ref = [ratio] * len(y_pred)\n",
    "    BS = brier_score_loss(y_true, y_pred_sig)\n",
    "    BS_ref = brier_score_loss(y_true, predictions_ref)\n",
    "    BS_skill = 1 - float(BS)/BS_ref\n",
    "\n",
    "    return BS_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(pred, true, labels=[0, 1]):\n",
    "    pred = pred.numpy()\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "    y_true = true.numpy()\n",
    "    \n",
    "    unique_label = np.unique([y_true, y_pred])\n",
    "    cmtx = pd.DataFrame(\n",
    "        confusion_matrix(y_true, y_pred, labels=unique_label), \n",
    "        index=['true:{:}'.format(x) for x in unique_label], \n",
    "        columns=['pred:{:}'.format(x) for x in unique_label]\n",
    "    )\n",
    "    print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_allNaN(tensor):\n",
    "    all_Nan = torch.isnan(tensor).all()\n",
    "    if all_Nan:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='weight.pt'):\n",
    "    \"\"\"\n",
    "    Save the training model\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class define_NN_model(object):\n",
    "    def __init__(self, h_sizes, drop_r, out_size):\n",
    "        self.h_sizes = h_sizes\n",
    "        self.drop_r = drop_r\n",
    "        self.out_size = out_size\n",
    "    \n",
    "    def def_model(self):\n",
    "        model = mlp(self.h_sizes, self.drop_r, self.out_size)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decreasing_lr, gamma=0.1)\n",
    "        \n",
    "        return model, optimizer, scheduler\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand target labels to one hot encoding\n",
    "\n",
    "# Example:\n",
    "#target = torch.ones([10, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "#output = torch.full([10, 2], 1.5)  # A prediction (logit)\n",
    "#pos_weight = torch.ones([2])  # All weights are equal to 1\n",
    "#criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "def criterion_ExpandTarget(output, target, criterion):\n",
    "\n",
    "    nb_classes = 2\n",
    "    batch_size = output.size()[0]\n",
    "    \n",
    "    #target_one_hot = torch.nn.functional.one_hot(target.to(torch.int64))\n",
    "    \n",
    "    target_one_hot = torch.FloatTensor(batch_size, nb_classes)\n",
    "    target_one_hot.zero_()\n",
    "    target_one_hot = target_one_hot.cuda()\n",
    "    \n",
    "    target = target.view(-1,1)\n",
    "    \n",
    "    target_one_hot.scatter_(1, target, 1)\n",
    "    \n",
    "    loss = criterion(output, target_one_hot.type_as(output)) \n",
    "    #loss = criterion(output, target)\n",
    "    \n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== below ================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args, best_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=440, data_dir='trans_data', decreasing_lr='60,80', drop_r=0.3, epochs=20, gpu=3, load_model=False, lr=0.058711765521739734, lr_Plateau_factor=0.4937429181024774, lr_Plateau_patience=8, momentum=0.11292347293920574, out_size=2, print_freq=200, save_dir='output', seed=1, weight_decay=0.014324063825534989)\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebook input workaround\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=['--save_dir', 'output', \n",
    "                               '--data_dir', 'trans_data', \n",
    "                               '--gpu', '3', \n",
    "                               '--epochs', '20', \n",
    "                               '--load_model', 'False',\n",
    "                               '--seed', '1',\n",
    "                               '--lr', '0.058711765521739734',\n",
    "                               '--print_freq', '200',\n",
    "                               '--out_size', '2',\n",
    "                               '--batch_size', '440',\n",
    "                               '--weight_decay', '0.014324063825534989',\n",
    "                               '--momentum', '0.11292347293920574',\n",
    "                               '--lr_Plateau_factor', '0.4937429181024774',\n",
    "                               '--lr_Plateau_patience', '8',                               \n",
    "                              ])\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.out_size == 2:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = criterion.cuda()\n",
    "decreasing_lr = list(map(int, args.decreasing_lr.split(',')))\n",
    "\n",
    "\n",
    "\n",
    "# model = mlp(h_sizes, args.drop_r, args.out_size)\n",
    "# model.cuda()\n",
    "\n",
    "starting_epoch = 0\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decreasing_lr, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 01:49:56 PM  XGB AUC=0.723\t:\n",
      "XGB_bal AUC=0.727\t:\n",
      "RF AUC=0.736\n",
      ":\n",
      "RF_bal AUC=0.719\n",
      ":\n",
      "Before temperature - NLL: 0.673, ECE: 0.147\n",
      "Optimal temperature: 1.496\n",
      "After temperature - NLL: 0.679, ECE: 0.156\n",
      "balanced calibrated: -0.02846443304665458\n",
      "Before temperature - NLL: 0.672, ECE: 0.142\n",
      "Optimal temperature: 1.495\n",
      "After temperature - NLL: 0.679, ECE: 0.150\n",
      "imbalanced calibrated: -0.038365347094644786\n",
      "AUC= -0.4834810408252259\n",
      "Fold 1: 01:52:02 PM  XGB AUC=0.723\t:\n",
      "XGB_bal AUC=0.743\t:\n",
      "RF AUC=0.764\n",
      ":\n",
      "RF_bal AUC=0.790\n",
      ":\n",
      "Before temperature - NLL: 0.672, ECE: 0.194\n",
      "Optimal temperature: 1.495\n",
      "After temperature - NLL: 0.679, ECE: 0.200\n",
      "balanced calibrated: -0.035181240794668556\n",
      "Before temperature - NLL: 0.667, ECE: 0.222\n",
      "Optimal temperature: 1.494\n",
      "After temperature - NLL: 0.676, ECE: 0.229\n",
      "imbalanced calibrated: -0.029648683226097594\n",
      "AUC= -0.46905178211806087\n",
      "Fold 2: 01:54:08 PM  XGB AUC=0.706\t:\n",
      "XGB_bal AUC=0.728\t:\n",
      "RF AUC=0.757\n",
      ":\n",
      "RF_bal AUC=0.719\n",
      ":\n",
      "Before temperature - NLL: 0.678, ECE: 0.119\n",
      "Optimal temperature: 1.497\n",
      "After temperature - NLL: 0.683, ECE: 0.125\n",
      "balanced calibrated: -0.05077441525993809\n",
      "Before temperature - NLL: 0.661, ECE: 0.227\n",
      "Optimal temperature: 1.493\n",
      "After temperature - NLL: 0.671, ECE: 0.235\n",
      "imbalanced calibrated: -0.032537621898808045\n",
      "AUC= -0.4903007277480307\n",
      "Fold 3: 01:56:10 PM  XGB AUC=0.716\t:\n",
      "XGB_bal AUC=0.660\t:\n",
      "RF AUC=0.735\n",
      ":\n",
      "RF_bal AUC=0.699\n",
      ":\n",
      "Before temperature - NLL: 0.678, ECE: 0.119\n",
      "Optimal temperature: 1.497\n",
      "After temperature - NLL: 0.683, ECE: 0.125\n",
      "balanced calibrated: -0.03626765913450414\n",
      "Before temperature - NLL: 0.660, ECE: 0.207\n",
      "Optimal temperature: 1.493\n",
      "After temperature - NLL: 0.671, ECE: 0.217\n",
      "imbalanced calibrated: -0.038344989033452626\n",
      "AUC= -0.48542400401609287\n",
      "Fold 4: 01:58:08 PM  XGB AUC=0.673\t:\n",
      "XGB_bal AUC=0.697\t:\n",
      "RF AUC=0.704\n",
      ":\n",
      "RF_bal AUC=0.643\n",
      ":\n",
      "Before temperature - NLL: 0.676, ECE: 0.201\n",
      "Optimal temperature: 1.496\n",
      "After temperature - NLL: 0.682, ECE: 0.206\n",
      "balanced calibrated: -0.04080607780285317\n",
      "Before temperature - NLL: 0.667, ECE: 0.192\n",
      "Optimal temperature: 1.494\n",
      "After temperature - NLL: 0.675, ECE: 0.199\n",
      "imbalanced calibrated: -0.03616020750538995\n",
      "AUC= -0.48768638535034214\n",
      "                0         1         2         3         4  lower_ci      mean  \\\n",
      "xgb      0.722990  0.723400  0.706369  0.716129  0.672945  0.700147  0.708367   \n",
      "xgb_bal  0.727291  0.742755  0.728184  0.659729  0.696670  0.697920  0.710926   \n",
      "rf       0.735535  0.764107  0.756876  0.735068  0.704370  0.730047  0.739191   \n",
      "rf_bal   0.718792  0.790271  0.719500  0.699376  0.643132  0.693558  0.714214   \n",
      "res     -0.483481 -0.469052 -0.490301 -0.485424 -0.487686 -0.486443 -0.483189   \n",
      "\n",
      "         upper_ci  \n",
      "xgb      0.716586  \n",
      "xgb_bal  0.723932  \n",
      "rf       0.748335  \n",
      "rf_bal   0.734870  \n",
      "res     -0.479934  \n"
     ]
    }
   ],
   "source": [
    "'''lr = args.lr\n",
    "factor_ls = np.array([0.00001, 0.000001, 0.0000001, 0.00000001])\n",
    "new_lr_ls = factor_ls * lr\n",
    "    \n",
    "for lr in new_lr_ls:\n",
    "    args.lr = lr\n",
    "'''\n",
    "args.lr *= 0.00000001\n",
    "\n",
    "# all below original\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "auc_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(df, labels)):\n",
    "    best_prec1_fold = -100\n",
    "    best_prec1 = -100\n",
    "\n",
    "    ########## prepare data ##################\n",
    "    print(f'Fold {i}: {datetime.datetime.now().strftime(\"%I:%M:%S %p\")}  ', end='')\n",
    "    train_data = df.iloc[train].copy()\n",
    "    test_data = df.iloc[test].copy()\n",
    "\n",
    "    train_labels=labels.iloc[train].copy()\n",
    "    test_labels=labels.iloc[test].copy()\n",
    "\n",
    "    weights = len(train_labels)/test_labels.sum()\n",
    "    glm_weights = pd.Series(data=1, index=train_labels.index)\n",
    "    glm_weights.loc[train_labels==1] = weights\n",
    "\n",
    "    ## preprocessing: remove ID/label/std=0 columns, mean imputation, normalization\n",
    "    train_id = train_data['ID'].copy()\n",
    "    test_id = test_data['ID'].copy()\n",
    "\n",
    "    train_data.drop(columns=outcome_cols+['ID'], inplace=True)\n",
    "    test_data.drop(columns= outcome_cols+['ID'], inplace=True)\n",
    "\n",
    "    #print(f'Fold {i} Imputation')\n",
    "    #imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    #train_data.values = imp.fit_transform(train_data)\n",
    "    #test_data.values  = imp.transform(test_data)\n",
    "    test_data = test_data.fillna(train_data.mean())\n",
    "    train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "    sd_0_cols = train_data.columns[(train_data.std() == 0)]\n",
    "    train_data.drop(columns=sd_0_cols, inplace=True)\n",
    "    test_data.drop(columns=sd_0_cols, inplace=True)\n",
    "\n",
    "    cols_to_scale = [foo for foo in con_cat_cols + contin_cols if foo in train_data.columns]\n",
    "    scaler = StandardScaler()\n",
    "    train_data.loc[:,cols_to_scale] = scaler.fit_transform(train_data.loc[:,cols_to_scale])\n",
    "    test_data.loc[:,cols_to_scale]  = scaler.transform(test_data.loc[:,cols_to_scale])\n",
    "\n",
    "    ############# prepare data for balanced batch ###############\n",
    "    pos_idx = np.where(train_labels == 1)[0]\n",
    "    neg_idx = np.where(train_labels == 0)[0]\n",
    "\n",
    "    train_data_pos = torch.Tensor(train_data.iloc[pos_idx].values)\n",
    "    train_data_neg = torch.Tensor(train_data.iloc[neg_idx].values)\n",
    "    train_data_t = torch.Tensor(train_data.values)\n",
    "\n",
    "    train_label_pos = torch.Tensor(train_labels.iloc[pos_idx].values)\n",
    "    train_label_neg = torch.Tensor(train_labels.iloc[neg_idx].values)\n",
    "    train_labels_t = torch.Tensor(train_labels.values)\n",
    "\n",
    "    train_Dataset_pos = TensorDataset(train_data_pos, train_label_pos)\n",
    "    train_Dataset_neg = TensorDataset(train_data_neg, train_label_neg)\n",
    "    train_Dataset = TensorDataset(train_data_t, train_labels_t)\n",
    "\n",
    "    train_loader_pos = DataLoader(train_Dataset_pos, batch_size=int(args.batch_size/2), shuffle=True, num_workers=2, pin_memory=True)\n",
    "    train_loader_neg = DataLoader(train_Dataset_neg, batch_size=int(args.batch_size/2), shuffle=True, num_workers=2, pin_memory=True)\n",
    "    train_loader = DataLoader(train_Dataset, batch_size=args.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    ############# prepare data for balanced batch (validation) ###############\n",
    "    pos_idx = np.where(test_labels == 1)[0]\n",
    "    neg_idx = np.where(test_labels == 0)[0]\n",
    "    neg_idx = np.random.choice(neg_idx, len(pos_idx))\n",
    "    \n",
    "    test_data_pos = torch.Tensor(test_data.iloc[pos_idx].values)\n",
    "    test_data_neg = torch.Tensor(test_data.iloc[neg_idx].values)\n",
    "    test_data_bal = torch.cat((test_data_pos, test_data_neg), 0)\n",
    "    test_labels_pos = torch.Tensor(test_labels.iloc[pos_idx].values).long()\n",
    "    test_labels_neg = torch.Tensor(test_labels.iloc[neg_idx].values).long()\n",
    "    test_labels_bal = torch.cat((test_labels_pos, test_labels_neg), 0)\n",
    "    valid_Dataset_bal = TensorDataset(test_data_bal, test_labels_bal)\n",
    "    val_loader_bal = DataLoader(valid_Dataset_bal, batch_size=args.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "\n",
    "    valid_data_t = torch.Tensor(test_data.values)\n",
    "    test_labels_t = torch.Tensor(test_labels.values).long()\n",
    "    valid_Dataset = TensorDataset(valid_data_t, test_labels_t)\n",
    "    val_loader = DataLoader(valid_Dataset, batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    ############# prepare balanced data for XGB/RF ###############\n",
    "    oversample = SMOTE(sampling_strategy='auto')\n",
    "    train_data_bal, train_labels_bal = oversample.fit_resample(train_data, train_labels)\n",
    "\n",
    "    ############ XGB ################\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    print(f'XGB AUC={auc:.3f}\\t:')\n",
    "    if i == 0:\n",
    "        auc_df['xgb'] = np.nan\n",
    "    auc_df['xgb'].iloc[i] = auc\n",
    "\n",
    "    ############ XGB_bal ################\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb.fit(train_data_bal, train_labels_bal)\n",
    "    auc = roc_auc_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    print(f'XGB_bal AUC={auc:.3f}\\t:')\n",
    "    if i == 0:\n",
    "        auc_df['xgb_bal'] = np.nan\n",
    "    auc_df['xgb_bal'].iloc[i] = auc\n",
    "\n",
    "    ############ RF ################\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    print(f'RF AUC={auc:.3f}\\n:')\n",
    "    if i == 0:\n",
    "        auc_df['rf'] = np.nan\n",
    "    auc_df['rf'].iloc[i] = auc\n",
    "\n",
    "    ############ RF ################\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(train_data_bal, train_labels_bal)\n",
    "    auc = roc_auc_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    print(f'RF_bal AUC={auc:.3f}\\n:')\n",
    "    if i == 0:\n",
    "        auc_df['rf_bal'] = np.nan\n",
    "    auc_df['rf_bal'].iloc[i] = auc\n",
    "\n",
    "    ############ ResBlock ################\n",
    "    \"\"\"\n",
    "    model = torch.load('Auto-PyTorch/examples/basics/TOPCAT_search.pt')\n",
    "    model.cuda()\n",
    "    auroc_meter = AverageMeter()\n",
    "    for data, target in val_loader:\n",
    "        data = data.cuda()\n",
    "        target = target.long().cuda()\n",
    "        output = model(data)\n",
    "        output = torch.sigmoid(output)\n",
    "        #aurocsore = auroc(output.data[:,1], target) \n",
    "        #aurocsore = aucpr(output.data.cpu(), target.cpu()) \n",
    "        aurocsore = brierskillscore(output.data.cpu()[:,1], target.cpu()) \n",
    "        auroc_meter.update(aurocsore, target.size(0))\n",
    "    #print(auroc_meter.avg.cpu().detach().numpy())\n",
    "    print(auroc_meter.avg)\n",
    "    if i == 0:\n",
    "        auc_df['res'] = np.nan\n",
    "    #auc_df['res'].iloc[i] = auroc_meter.avg.cpu().detach().numpy()\n",
    "    auc_df['res'].iloc[i] = auroc_meter.avg\n",
    "    \"\"\"\n",
    "    model = Appended_Model(last_in=79, last_out=2)\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=args.lr_Plateau_factor, patience=args.lr_Plateau_patience)\n",
    "\n",
    "\n",
    "    # [index, acc]\n",
    "    train_acc_bal = [[],[]]\n",
    "    train_acc_rand = [[],[]]\n",
    "    ta_bal = [[],[]]\n",
    "    ta_imba = [[],[]]\n",
    "\n",
    "    for epoch in range(starting_epoch, starting_epoch + args.epochs):\n",
    "        loss_rand_train, loss_bal_train, top1_bal_train, top1_rand_train = training(train_loader, train_loader_pos, train_loader_neg, model, criterion, optimizer, epoch)\n",
    "\n",
    "\n",
    "        loss_bal_test, prec1_bal_test = validate(val_loader_bal, model, criterion, if_main=True)\n",
    "        loss_rand_test, prec1_imba_test = validate(val_loader, model, criterion, if_main=False)\n",
    "        prec1_bal_test = prec1_imba_test\n",
    "\n",
    "        train_acc_bal[0].append(epoch)\n",
    "        train_acc_rand[0].append(epoch)\n",
    "        ta_bal[0].append(epoch)\n",
    "        ta_imba[0].append(epoch)\n",
    "\n",
    "        train_acc_bal[1].append(top1_bal_train)\n",
    "        train_acc_rand[1].append(top1_rand_train)\n",
    "        ta_bal[1].append(prec1_bal_test)\n",
    "        ta_imba[1].append(prec1_imba_test)\n",
    "\n",
    "        scheduler.step(metrics=prec1_bal_test)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        # balanced, testing result\n",
    "        if prec1_bal_test > best_prec1:\n",
    "            is_best = prec1_bal_test > best_prec1\n",
    "            best_prec1 = max(prec1_bal_test, best_prec1)\n",
    "            best_epoch = epoch\n",
    "\n",
    "        if is_best:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "            }, filename=os.path.join(args.save_dir, 'best_model.pt'))\n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "        }, filename=os.path.join(args.save_dir, 'checkpoint.pt'))\n",
    "\n",
    "        plt.plot(train_acc_bal[0], train_acc_bal[1], label='train_acc_bal')\n",
    "        plt.plot(train_acc_rand[0], train_acc_rand[1], label='train_acc_rand')\n",
    "        plt.plot(ta_imba[0], ta_imba[1], label='TA_imba')\n",
    "        plt.plot(ta_bal[0], ta_bal[1], label='TA_bal')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(args.save_dir, 'net_train.png'))\n",
    "        if is_best:\n",
    "            plt.savefig(os.path.join(args.save_dir, 'net_train_best_epoch'+ str(epoch) + '.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # for dataframe\n",
    "        auc = best_prec1\n",
    "        if best_prec1 < best_prec1_fold:\n",
    "            auc = best_prec1_fold\n",
    "        else:\n",
    "            best_prec1_fold = best_prec1\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # quick validation (when without validation function)\n",
    "    auroc_meter = AverageMeter()\n",
    "    model.eval()\n",
    "    for data, target in val_loader:\n",
    "        data = data.cuda()\n",
    "        target = target.long().cuda()\n",
    "        output = model(data)\n",
    "        output = torch.sigmoid(output)\n",
    "        aurocsore = auroc(output.data[:,1], target) \n",
    "        auroc_meter.update(aurocsore, target.size(0))\n",
    "    print(auroc_meter.avg.cpu().detach().numpy())\n",
    "    '''\n",
    "\n",
    "    if i == 0:\n",
    "        auc_df['res'] = np.nan\n",
    "\n",
    "    '''\n",
    "    # only quick test\n",
    "    auc_df['res'].iloc[i] = auroc_meter.avg.cpu().detach().numpy()\n",
    "    '''\n",
    "    \n",
    "    # use temperature scaling: \n",
    "    # https://github.com/gpleiss/temperature_scaling\n",
    "    scaled_model_bal = ModelWithTemperature(model)\n",
    "    scaled_model_bal.set_temperature(val_loader_bal)\n",
    "    loss_bal_test, prec1_bal_test = validate(val_loader_bal, model, criterion, if_main=True)\n",
    "    print('balanced calibrated: ' + str(prec1_bal_test))\n",
    "    \n",
    "    scaled_model = ModelWithTemperature(model)\n",
    "    scaled_model.set_temperature(val_loader)\n",
    "    loss_bal_test, prec1_bal_test = validate(val_loader_bal, model, criterion, if_main=True)\n",
    "    print('imbalanced calibrated: ' + str(prec1_bal_test))\n",
    "    \n",
    "    \n",
    "    # real training\n",
    "    auc_df['res'].iloc[i] = best_prec1_fold\n",
    "    print('AUC=', best_prec1_fold)\n",
    "\n",
    "\n",
    "auc_scores = auc_df.T\n",
    "auc_scores['lower_ci'] = auc_df.T.mean(axis=1) - 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "auc_scores['mean'] = auc_df.T.mean(axis=1)\n",
    "auc_scores['upper_ci'] = auc_df.T.mean(axis=1) + 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "#auc_scores.sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(auc_scores)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 02:00:07 PM  [14:00:08] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB AUC=0.723\t:\n",
      "[14:00:25] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB_bal AUC=0.723\t:\n",
      "RF AUC=0.696\n",
      ":\n",
      "RF_bal AUC=0.737\n",
      ":\n",
      "Fold 1: 02:00:43 PM  [14:00:44] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB AUC=0.723\t:\n",
      "[14:01:01] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB_bal AUC=0.723\t:\n",
      "RF AUC=0.772\n",
      ":\n",
      "RF_bal AUC=0.770\n",
      ":\n",
      "Fold 2: 02:01:19 PM  [14:01:20] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB AUC=0.706\t:\n",
      "[14:01:37] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB_bal AUC=0.706\t:\n",
      "RF AUC=0.758\n",
      ":\n",
      "RF_bal AUC=0.759\n",
      ":\n",
      "Fold 3: 02:01:55 PM  [14:01:56] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB AUC=0.716\t:\n",
      "[14:02:13] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB_bal AUC=0.716\t:\n",
      "RF AUC=0.676\n",
      ":\n",
      "RF_bal AUC=0.725\n",
      ":\n",
      "Fold 4: 02:02:31 PM  [14:02:31] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB AUC=0.673\t:\n",
      "[14:02:49] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB_bal AUC=0.673\t:\n",
      "RF AUC=0.681\n",
      ":\n",
      "RF_bal AUC=0.699\n",
      ":\n",
      "                0         1         2         3         4  lower_ci      mean  \\\n",
      "xgb      0.722990  0.723400  0.706369  0.716129  0.672945  0.700147  0.708367   \n",
      "xgb_bal  0.722990  0.723400  0.706369  0.716129  0.672945  0.700147  0.708367   \n",
      "rf       0.695801  0.772094  0.758065  0.675963  0.681322  0.698979  0.716649   \n",
      "rf_bal   0.736713  0.769790  0.758685  0.725130  0.698959  0.726890  0.737855   \n",
      "\n",
      "         upper_ci  \n",
      "xgb      0.716586  \n",
      "xgb_bal  0.716586  \n",
      "rf       0.734319  \n",
      "rf_bal   0.748821  \n"
     ]
    }
   ],
   "source": [
    "# all below original\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "auc_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(df, labels)):\n",
    "    best_prec1_fold = 0\n",
    "\n",
    "    ########## prepare data ##################\n",
    "    print(f'Fold {i}: {datetime.datetime.now().strftime(\"%I:%M:%S %p\")}  ', end='')\n",
    "    train_data = df.iloc[train].copy()\n",
    "    test_data = df.iloc[test].copy()\n",
    "\n",
    "    train_labels=labels.iloc[train].copy()\n",
    "    test_labels=labels.iloc[test].copy()\n",
    "\n",
    "    weights = len(train_labels)/test_labels.sum()\n",
    "    glm_weights = pd.Series(data=1, index=train_labels.index)\n",
    "    glm_weights.loc[train_labels==1] = weights\n",
    "\n",
    "    ## preprocessing: remove ID/label/std=0 columns, mean imputation, normalization\n",
    "    train_id = train_data['ID'].copy()\n",
    "    test_id = test_data['ID'].copy()\n",
    "\n",
    "    train_data.drop(columns=outcome_cols+['ID'], inplace=True)\n",
    "    test_data.drop(columns= outcome_cols+['ID'], inplace=True)\n",
    "\n",
    "    #print(f'Fold {i} Imputation')\n",
    "    #imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    #train_data.values = imp.fit_transform(train_data)\n",
    "    #test_data.values  = imp.transform(test_data)\n",
    "    test_data = test_data.fillna(train_data.mean())\n",
    "    train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "    sd_0_cols = train_data.columns[(train_data.std() == 0)]\n",
    "    train_data.drop(columns=sd_0_cols, inplace=True)\n",
    "    test_data.drop(columns=sd_0_cols, inplace=True)\n",
    "\n",
    "    cols_to_scale = [foo for foo in con_cat_cols + contin_cols if foo in train_data.columns]\n",
    "    scaler = StandardScaler()\n",
    "    train_data.loc[:,cols_to_scale] = scaler.fit_transform(train_data.loc[:,cols_to_scale])\n",
    "    test_data.loc[:,cols_to_scale]  = scaler.transform(test_data.loc[:,cols_to_scale])\n",
    "\n",
    "    ############# prepare data for balanced batch ###############\n",
    "    pos_idx = np.where(train_labels == 1)[0]\n",
    "    neg_idx = np.where(train_labels == 0)[0]\n",
    "\n",
    "    train_data_pos = torch.Tensor(train_data.iloc[pos_idx].values)\n",
    "    train_data_neg = torch.Tensor(train_data.iloc[neg_idx].values)\n",
    "    train_data_t = torch.Tensor(train_data.values)\n",
    "\n",
    "    train_label_pos = torch.Tensor(train_labels.iloc[pos_idx].values)\n",
    "    train_label_neg = torch.Tensor(train_labels.iloc[neg_idx].values)\n",
    "    train_labels_t = torch.Tensor(train_labels.values)\n",
    "\n",
    "    train_Dataset_pos = TensorDataset(train_data_pos, train_label_pos)\n",
    "    train_Dataset_neg = TensorDataset(train_data_neg, train_label_neg)\n",
    "    train_Dataset = TensorDataset(train_data_t, train_labels_t)\n",
    "\n",
    "    train_loader_pos = DataLoader(train_Dataset_pos, batch_size=int(args.batch_size/2), shuffle=True, num_workers=2, pin_memory=True)\n",
    "    train_loader_neg = DataLoader(train_Dataset_neg, batch_size=int(args.batch_size/2), shuffle=True, num_workers=2, pin_memory=True)\n",
    "    train_loader = DataLoader(train_Dataset, batch_size=args.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    ############# prepare data for balanced batch (validation) ###############\n",
    "    pos_idx = np.where(test_labels == 1)[0]\n",
    "    neg_idx = np.where(test_labels == 0)[0]\n",
    "    neg_idx = np.random.choice(neg_idx, len(pos_idx))\n",
    "    \n",
    "    test_data_pos = torch.Tensor(test_data.iloc[pos_idx].values)\n",
    "    test_data_neg = torch.Tensor(test_data.iloc[neg_idx].values)\n",
    "    test_data_bal = torch.cat((test_data_pos, test_data_neg), 0)\n",
    "    test_labels_pos = torch.Tensor(test_labels.iloc[pos_idx].values)\n",
    "    test_labels_neg = torch.Tensor(test_labels.iloc[neg_idx].values)\n",
    "    test_labels_bal = torch.cat((test_labels_pos, test_labels_neg), 0)\n",
    "    valid_Dataset_bal = TensorDataset(test_data_bal, test_labels_bal)\n",
    "    val_loader_bal = DataLoader(valid_Dataset_bal, batch_size=args.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "\n",
    "    valid_data_t = torch.Tensor(test_data.values)\n",
    "    test_labels_t = torch.Tensor(test_labels.values)\n",
    "    valid_Dataset = TensorDataset(valid_data_t, test_labels_t)\n",
    "    val_loader = DataLoader(valid_Dataset, batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    ############# prepare balanced data for XGB/RF ###############\n",
    "    oversample = SMOTE(sampling_strategy='not minority')\n",
    "    train_data_bal, train_labels_bal = oversample.fit_resample(train_data, train_labels)\n",
    "\n",
    "    ############ XGB ################\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    print(f'XGB AUC={auc:.3f}\\t:')\n",
    "    if i == 0:\n",
    "        auc_df['xgb'] = np.nan\n",
    "    auc_df['xgb'].iloc[i] = auc\n",
    "\n",
    "    ############ XGB_bal ################\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(train_data_bal, train_labels_bal)\n",
    "    auc = roc_auc_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    print(f'XGB_bal AUC={auc:.3f}\\t:')\n",
    "    if i == 0:\n",
    "        auc_df['xgb_bal'] = np.nan\n",
    "    auc_df['xgb_bal'].iloc[i] = auc\n",
    "\n",
    "    ############ RF ################\n",
    "    #rf = RandomForestClassifier()\n",
    "    rf = BalancedRandomForestClassifier()\n",
    "    rf.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    print(f'RF AUC={auc:.3f}\\n:')\n",
    "    if i == 0:\n",
    "        auc_df['rf'] = np.nan\n",
    "    auc_df['rf'].iloc[i] = auc\n",
    "\n",
    "    ############ RF ################\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(train_data_bal, train_labels_bal)\n",
    "    auc = roc_auc_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    print(f'RF_bal AUC={auc:.3f}\\n:')\n",
    "    if i == 0:\n",
    "        auc_df['rf_bal'] = np.nan\n",
    "    auc_df['rf_bal'].iloc[i] = auc\n",
    "\n",
    "\n",
    "auc_scores = auc_df.T\n",
    "auc_scores['lower_ci'] = auc_df.T.mean(axis=1) - 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "auc_scores['mean'] = auc_df.T.mean(axis=1)\n",
    "auc_scores['upper_ci'] = auc_df.T.mean(axis=1) + 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "#auc_scores.sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(auc_scores)    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb</th>\n",
       "      <th>xgb_bal</th>\n",
       "      <th>rf</th>\n",
       "      <th>rf_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.736713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.772094</td>\n",
       "      <td>0.769790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.706369</td>\n",
       "      <td>0.706369</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.758685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.725130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672945</td>\n",
       "      <td>0.672945</td>\n",
       "      <td>0.681322</td>\n",
       "      <td>0.698959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xgb   xgb_bal        rf    rf_bal\n",
       "0  0.722990  0.722990  0.695801  0.736713\n",
       "1  0.723400  0.723400  0.772094  0.769790\n",
       "2  0.706369  0.706369  0.758065  0.758685\n",
       "3  0.716129  0.716129  0.675963  0.725130\n",
       "4  0.672945  0.672945  0.681322  0.698959"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.706369</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.672945</td>\n",
       "      <td>0.700147</td>\n",
       "      <td>0.708367</td>\n",
       "      <td>0.716586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_bal</th>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.706369</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.672945</td>\n",
       "      <td>0.700147</td>\n",
       "      <td>0.708367</td>\n",
       "      <td>0.716586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.772094</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.675963</td>\n",
       "      <td>0.681322</td>\n",
       "      <td>0.698979</td>\n",
       "      <td>0.716649</td>\n",
       "      <td>0.734319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bal</th>\n",
       "      <td>0.736713</td>\n",
       "      <td>0.769790</td>\n",
       "      <td>0.758685</td>\n",
       "      <td>0.725130</td>\n",
       "      <td>0.698959</td>\n",
       "      <td>0.726890</td>\n",
       "      <td>0.737855</td>\n",
       "      <td>0.748821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4  lower_ci      mean  \\\n",
       "xgb      0.722990  0.723400  0.706369  0.716129  0.672945  0.700147  0.708367   \n",
       "xgb_bal  0.722990  0.723400  0.706369  0.716129  0.672945  0.700147  0.708367   \n",
       "rf       0.695801  0.772094  0.758065  0.675963  0.681322  0.698979  0.716649   \n",
       "rf_bal   0.736713  0.769790  0.758685  0.725130  0.698959  0.726890  0.737855   \n",
       "\n",
       "         upper_ci  \n",
       "xgb      0.716586  \n",
       "xgb_bal  0.716586  \n",
       "rf       0.734319  \n",
       "rf_bal   0.748821  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# two sets of learning rates\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "\n",
    "model = [Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "optimizer = SGD(model, 0.1)\n",
    "\n",
    "scheduler1 = ExponentialLR(optimizer, gamma=0.9)\n",
    "scheduler2 = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    print(epoch, scheduler2.get_last_lr()[0])\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Nate's search (delete)\n",
    "'''\n",
    "    ########### MLP #################\n",
    "    for hl_count in [1, 2, 3, 4]:\n",
    "        print(f'\\t{hl_count} HL(s): ', end='')\n",
    "        for hl_size in np.linspace(30,150,dtype=int, num=6):\n",
    "            best_prec1 = 0\n",
    "            \n",
    "            h_sizes = [79] + [hl_size for x in range(hl_count)]\n",
    "            \n",
    "            #define model, optimizer, scheduler\n",
    "            NN_model = define_NN_model(h_sizes, args.drop_r, args.out_size)\n",
    "            model, optimizer, scheduler = NN_model.def_model()\n",
    "            #model = torch.load('Auto-PyTorch/examples/basics/TOPCAT_search.pt')\n",
    "            model.cuda()\n",
    "\n",
    "            # index, acc\n",
    "            train_acc = [[],[]]\n",
    "            ta_bal = [[],[]]\n",
    "            ta_imba = [[],[]]\n",
    "\n",
    "            for epoch in range(starting_epoch, starting_epoch + args.epochs):\n",
    "                train_accuracy = training(train_loader, train_loader_pos, train_loader_neg, model, criterion, optimizer, epoch)\n",
    "\n",
    "                prec1_bal = validate(val_loader, model, criterion, if_main=True)\n",
    "                prec1_imba = validate(val_loader, model, criterion, if_main=False)\n",
    "\n",
    "                train_acc[0].append(epoch)\n",
    "                ta_bal[0].append(epoch)\n",
    "                ta_imba[0].append(epoch)\n",
    "\n",
    "                train_acc[1].append(train_accuracy)\n",
    "                ta_bal[1].append(prec1_bal)\n",
    "                ta_imba[1].append(prec1_imba)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                # remember best prec@1 and save checkpoint\n",
    "                if prec1_bal > best_prec1:\n",
    "                    is_best = prec1_bal > best_prec1\n",
    "                    best_prec1 = max(prec1_bal, best_prec1)\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                if is_best:\n",
    "                    save_checkpoint({\n",
    "                        'epoch': epoch + 1,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'best_prec1': best_prec1,\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'scheduler': scheduler.state_dict(),\n",
    "                    }, filename=os.path.join(args.save_dir, 'best_model.pt'))\n",
    "\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_prec1': best_prec1,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict(),\n",
    "                }, filename=os.path.join(args.save_dir, 'checkpoint.pt'))\n",
    "\n",
    "                plt.plot(train_acc[0], train_acc[1], label='train_acc')\n",
    "                plt.plot(ta_imba[0], ta_imba[1], label='TA_imba')\n",
    "                plt.plot(ta_bal[0], ta_bal[1], label='TA_bal')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.savefig(os.path.join(args.save_dir, 'net_train.png'))\n",
    "                if is_best:\n",
    "                    plt.savefig(os.path.join(args.save_dir, 'net_train_'+ f'{hl_count}_{hl_size}' +'.png'))\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "            \n",
    "            auc = best_prec1\n",
    "            print(f'size{hl_size}=> AUC={auc:.3f} ({best_epoch} epochs) ', end='')\n",
    "            if best_prec1 < best_prec1_fold:\n",
    "                auc = best_prec1_fold\n",
    "            else:\n",
    "                best_prec1_fold = best_prec1\n",
    "            \n",
    "            \n",
    "        print()\n",
    "        \n",
    "    if i == 0:\n",
    "        auc_df['mlp'] = np.nan\n",
    "    auc_df['mlp'].iloc[i] = auc\n",
    "        \n",
    "    #to see in one fold first \n",
    "    break    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('py36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "763944e8a0f0ced878785a0a4fba7a66755afcae9e9bfcbb46e371437d18a427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
