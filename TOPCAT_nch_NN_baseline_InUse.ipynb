{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "import os, datetime\n",
    "import tempfile\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "#path = '/data/datasets/topcat/data/csv_data/'\n",
    "path = '/data/datasets/topcat/data/sas_data/'\n",
    "pathOutcomes = '/data/datasets/topcat/data/Outcomes/'\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from califorest.califorest import CaliForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brierskillscore(y_pred, y_true):\n",
    "    cls_num_list = np.unique(y_true, return_counts=True)[1]\n",
    "    ratio = float(cls_num_list[1]) / np.sum(cls_num_list)\n",
    "    y_true, y_pred = y_true.reshape(1,-1).squeeze(), y_pred.reshape(1,-1).squeeze()\n",
    "    y_pred_sig = 1/(1 + np.exp(-y_pred))\n",
    "    predictions_ref = [ratio] * len(y_pred)\n",
    "    BS = brier_score_loss(y_true, y_pred_sig)\n",
    "    BS_ref = brier_score_loss(y_true, predictions_ref)\n",
    "    BS_skill = 1 - float(BS)/BS_ref\n",
    "\n",
    "    print('ratio', ratio)\n",
    "    print('BS_ref', BS_ref)\n",
    "    print('BS', BS)\n",
    "    return BS_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_cols = [\n",
    "    'death', 'cvd_death', 'time_death', 'anyhosp', 'time_anyhosp',\n",
    "    'hfhosp', 'time_hfhosp', 'abortedca', 'time_abortedca', 'mi',\n",
    "    'time_mi', 'stroke', 'time_stroke', 'primary_ep', 'time_primary_ep'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cat_cols = [\n",
    "    'GLUCOSE_FAST', 'GLUCOSE_RAND', 'CO2_mmolL', 'GLUCOSE_mgdL','WBC_kuL',\n",
    "    'HCT_p', 'HB_gdL', 'PLT_kuL', 'ALP_UL', 'TBILI_mgdL', 'ALB_gdL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_cols = [\n",
    "    'BNP_VAL', 'age_entry', 'EF', 'visit_dt1_hf', 'chfdc_dt3', 'mi_dt3',\n",
    "    'stroke_dt3', 'cabg_dt3', 'pci_dt3', 'DM_AGE_YR', 'DM_DUR_YR', 'cigs',\n",
    "    'SMOKE_YRS', 'QUIT_YRS', 'HEAVY_MIN', 'HEAVY_WK', 'MED_WK', 'MED_MIN',\n",
    "    'LIGHT_WK', 'LIGHT_MIN', 'metsperweek', 'cooking_salt_score', 'height',\n",
    "    'weight', 'waistc', 'HR', 'SBP', 'DBP', 'CR_mgdl', 'gfr', 'labs_dt1',\n",
    "    'NA_mmolL', 'K_mmolL', 'CL_mmolL', 'BUN_mgdL', 'ALT_UL', 'AST_UL',\n",
    "    'urine_val_mgg', 'QRS_DUR', 'CR_mgdL', 'BMI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "priep = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/primary_ep_set.csv', index_col=0)\n",
    "death = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/death_set.csv'     , index_col=0)\n",
    "hfhos = pd.read_csv('/data/datasets/topcat/nch/nn_baseline/hfhosp_set.csv'    , index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 1:\n",
    "    outcome = 'primary_ep'\n",
    "    outcome_time = 'time_primary_ep'\n",
    "    df = priep.copy()\n",
    "elif mode == 2:\n",
    "    outcome = 'death'\n",
    "    outcome_time = 'time_death'\n",
    "    df = death.copy()\n",
    "elif mode == 3:\n",
    "    outcome = 'hfhosp'\n",
    "    outcome_time = 'time_hfhosp'\n",
    "    df = hfhos.copy()\n",
    "\n",
    "labels = df[outcome].copy()\n",
    "complete_labels = labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS = [\n",
    "  keras.metrics.TruePositives(name='tp'),\n",
    "  keras.metrics.FalsePositives(name='fp'),\n",
    "  keras.metrics.TrueNegatives(name='tn'),\n",
    "  keras.metrics.FalseNegatives(name='fn'), \n",
    "  keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "  keras.metrics.Precision(name='precision'),\n",
    "  keras.metrics.Recall(name='recall'),\n",
    "  keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def make_model(metrics = METRICS, output_bias=None, hl_count=1, hl_size=16, dropout=0.5):\n",
    "        if output_bias is not None:\n",
    "            output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(\n",
    "                hl_size, activation='relu',\n",
    "                input_shape=(train_data.shape[-1],)))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "        \n",
    "        for i in range(hl_count-1):\n",
    "            model.add(\n",
    "                keras.layers.Dense(hl_size, activation='relu'))\n",
    "            model.add(keras.layers.Dropout(dropout))\n",
    "        \n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid',\n",
    "                               bias_initializer=output_bias)\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "            loss=keras.losses.BinaryCrossentropy(),\n",
    "            metrics=metrics)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=0,\n",
    "    patience=200,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos_idx = np.where(train_labels == 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neg_idx = np.where(train_labels == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 06:47:03 PM  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.2889908256880734\n",
      "BS_ref 0.205475128356199\n",
      "BS 0.2723203624267018\n",
      "Fold 1: 06:47:04 PM  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.2889908256880734\n",
      "BS_ref 0.205475128356199\n",
      "BS 0.2729867463235877\n",
      "Fold 2: 06:47:05 PM  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.28440366972477066\n",
      "BS_ref 0.20351822237185416\n",
      "BS 0.27220696991113524\n",
      "Fold 3: 06:47:05 PM  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.2857142857142857\n",
      "BS_ref 0.20408163265306126\n",
      "BS 0.2731182754541424\n",
      "Fold 4: 06:47:06 PM  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/g/guangzhou92/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 0.2857142857142857\n",
      "BS_ref 0.20408163265306126\n",
      "BS 0.2773880586968818\n"
     ]
    }
   ],
   "source": [
    "auc_df = pd.DataFrame(index=range(5))\n",
    "auprc_df = pd.DataFrame(index=range(5))\n",
    "bss_df = pd.DataFrame(index=range(5))\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(df, labels)):\n",
    "    print(f'Fold {i}: {datetime.datetime.now().strftime(\"%I:%M:%S %p\")}  ', end='')\n",
    "    train_data = df.iloc[train].copy()\n",
    "    test_data = df.iloc[test].copy()\n",
    "    \n",
    "    train_labels=labels.iloc[train].copy()\n",
    "    test_labels=labels.iloc[test].copy()\n",
    "    \n",
    "    counts = np.unique(train_labels, return_counts=True)\n",
    "    weight_for_0 = 1.0 / counts[0]\n",
    "    weight_for_1 = 1.0 / counts[1]\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "    weights = len(train_labels)/test_labels.sum()\n",
    "    glm_weights = pd.Series(data=1, index=train_labels.index)\n",
    "    glm_weights.loc[train_labels==1] = weights\n",
    "    \n",
    "    #remove outcomes\n",
    "    train_id = train_data['ID'].copy()\n",
    "    test_id = test_data['ID'].copy()\n",
    "    \n",
    "    train_data.drop(columns=outcome_cols+['ID'], inplace=True)\n",
    "    test_data.drop(columns= outcome_cols+['ID'], inplace=True)\n",
    "    \n",
    "    #print(f'Fold {i} Imputation')\n",
    "    #imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    #train_data.values = imp.fit_transform(train_data)\n",
    "    #test_data.values  = imp.transform(test_data)\n",
    "    test_data = test_data.fillna(train_data.mean())\n",
    "    train_data = train_data.fillna(train_data.mean())\n",
    "    \n",
    "    sd_0_cols = train_data.columns[(train_data.std() == 0)]\n",
    "    train_data.drop(columns=sd_0_cols, inplace=True)\n",
    "    test_data.drop(columns=sd_0_cols, inplace=True)\n",
    "    \n",
    "    cols_to_scale = [foo for foo in con_cat_cols + contin_cols if foo in train_data.columns]\n",
    "    scaler = StandardScaler()\n",
    "    train_data.loc[:,cols_to_scale] = scaler.fit_transform(train_data.loc[:,cols_to_scale])\n",
    "    test_data.loc[:,cols_to_scale]  = scaler.transform(test_data.loc[:,cols_to_scale])\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    '''\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    #xgb_cali = CalibratedClassifierCV(base_estimator=xgb, method='isotonic', cv=3)\n",
    "    #xgb = xgb_cali\n",
    "    xgb.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    auprc = average_precision_score(test_labels, xgb.predict_proba(test_data)[:,1])\n",
    "    bss = brierskillscore(xgb.predict_proba(test_data)[:,1], test_labels.values)\n",
    "    #print(f'XGB AUC={auc:.3f}\\tNNs:')\n",
    "    #print(f'XGB AUPRC={auprc:.3f}\\tNNs:')\n",
    "    #print(f'XGB BSS={bss:.3f}\\tNNs:')\n",
    "    if i == 0:\n",
    "        auc_df['xgb'] = np.nan\n",
    "        auprc_df['xgb'] = np.nan\n",
    "        bss_df['xgb'] = np.nan\n",
    "    auc_df['xgb'].iloc[i] = auc\n",
    "    auprc_df['xgb'].iloc[i] = auprc\n",
    "    bss_df['xgb'].iloc[i] = bss\n",
    "    \n",
    "    ############################\n",
    "    rf = RandomForestClassifier()\n",
    "    #rf_cali = CalibratedClassifierCV(base_estimator=rf, method='isotonic', cv=3)\n",
    "    #rf = rf_cali\n",
    "    rf.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    auprc = average_precision_score(test_labels, rf.predict_proba(test_data)[:,1])\n",
    "    bss = brierskillscore(rf.predict_proba(test_data)[:,1], test_labels.values)\n",
    "    #print(f'RF AUC={auc:.3f}\\nNNs:')\n",
    "    #print(f'RF AUPRC={auprc:.3f}\\nNNs:')\n",
    "    #print(f'RF BSS={bss:.3f}\\nNNs:')\n",
    "    if i == 0:\n",
    "        auc_df['rf'] = np.nan\n",
    "        auprc_df['rf'] = np.nan\n",
    "        bss_df['rf'] = np.nan\n",
    "    auc_df['rf'].iloc[i] = auc\n",
    "    auprc_df['rf'].iloc[i] = auprc\n",
    "    bss_df['rf'].iloc[i] = bss\n",
    "    \n",
    "    ############################\n",
    "    rf_b = RUSBoostClassifier()\n",
    "    #rf_b_cali = CalibratedClassifierCV(base_estimator=rf_b, method='isotonic', cv=3)\n",
    "    #rf_b = rf_b_cali\n",
    "    rf_b.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, rf_b.predict_proba(test_data)[:,1])\n",
    "    auprc = average_precision_score(test_labels, rf_b.predict_proba(test_data)[:,1])\n",
    "    bss = brierskillscore(rf_b.predict_proba(test_data)[:,1], test_labels.values)\n",
    "    #print(f'RF AUC={auc:.3f}\\nNNs:')\n",
    "    #print(f'RF AUPRC={auprc:.3f}\\nNNs:')\n",
    "    #print(f'RF BSS={bss:.3f}\\nNNs:')\n",
    "    if i == 0:\n",
    "        auc_df['rf_b'] = np.nan\n",
    "        auprc_df['rf_b'] = np.nan\n",
    "        bss_df['rf_b'] = np.nan\n",
    "    auc_df['rf_b'].iloc[i] = auc\n",
    "    auprc_df['rf_b'].iloc[i] = auprc\n",
    "    bss_df['rf_b'].iloc[i] = bss\n",
    "    '''\n",
    "    ############################\n",
    "    califorest = CaliForest()\n",
    "    califorest.fit(train_data, train_labels)\n",
    "    auc = roc_auc_score(test_labels, califorest.predict_proba(test_data)[:,1])\n",
    "    auprc = average_precision_score(test_labels, califorest.predict_proba(test_data)[:,1])\n",
    "    bss = brierskillscore(califorest.predict_proba(test_data)[:,1], test_labels.values)\n",
    "    #print(f'RF AUC={auc:.3f}\\nNNs:')\n",
    "    #print(f'RF AUPRC={auprc:.3f}\\nNNs:')\n",
    "    #print(f'RF BSS={bss:.3f}\\nNNs:')\n",
    "    if i == 0:\n",
    "        auc_df['califorest'] = np.nan\n",
    "        auprc_df['califorest'] = np.nan\n",
    "        bss_df['califorest'] = np.nan\n",
    "    auc_df['califorest'].iloc[i] = auc\n",
    "    auprc_df['califorest'].iloc[i] = auprc\n",
    "    bss_df['califorest'].iloc[i] = bss\n",
    "    \n",
    "    ############################\n",
    "    '''\n",
    "    #for hl_count in [1,2,3,4]:\n",
    "    for hl_count in [1]:\n",
    "        print(f'\\t{hl_count} HL(s): ', end='')\n",
    "        #for hl_size in np.linspace(6,60,dtype=int, num=6):\n",
    "        for hl_size in [6]:\n",
    "            model = make_model(hl_count=hl_count, hl_size=hl_size)\n",
    "            name = f'{hl_count}_{hl_size}'\n",
    "            if name not in auc_df.columns:\n",
    "                auc_df[name] = np.nan\n",
    "            \n",
    "            baseline_history = model.fit(\n",
    "                train_data.values,\n",
    "                train_labels.values,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                callbacks = [early_stopping],\n",
    "                validation_data=(test_data.values, test_labels.values),\n",
    "                class_weight=class_weight,\n",
    "                verbose=0\n",
    "            )\n",
    "            auc = np.mean(baseline_history.history['val_auc'][-100:])\n",
    "            run_length = len(baseline_history.history['val_auc'])\n",
    "            auc_df[name].iloc[i] = auc\n",
    "            print(f'size{hl_size}=> AUC={auc:.3f} ({str(run_length).rjust(4)} epochs)   ', end='')\n",
    "        print()\n",
    "            \n",
    "    '''    \n",
    "    #pos = train_labels.sum()\n",
    "    #total = len(train_labels)\n",
    "    #neg = total - pos\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auprc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>califorest</th>\n",
       "      <td>0.735177</td>\n",
       "      <td>0.776907</td>\n",
       "      <td>0.758943</td>\n",
       "      <td>0.706191</td>\n",
       "      <td>0.684079</td>\n",
       "      <td>0.717443</td>\n",
       "      <td>0.73226</td>\n",
       "      <td>0.747077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4  lower_ci  \\\n",
       "califorest  0.735177  0.776907  0.758943  0.706191  0.684079  0.717443   \n",
       "\n",
       "               mean  upper_ci  \n",
       "califorest  0.73226  0.747077  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores = auc_df.T\n",
    "auc_scores['lower_ci'] = auc_df.T.mean(axis=1) - 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "auc_scores['mean'] = auc_df.T.mean(axis=1)\n",
    "auc_scores['upper_ci'] = auc_df.T.mean(axis=1) + 1.96*auc_df.T.std(axis=1)/auc_df.T.count(axis=1)\n",
    "#auc_scores.sort_values(by='mean', ascending=False)\n",
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>califorest</th>\n",
       "      <td>0.508045</td>\n",
       "      <td>0.522168</td>\n",
       "      <td>0.542909</td>\n",
       "      <td>0.466901</td>\n",
       "      <td>0.415518</td>\n",
       "      <td>0.47128</td>\n",
       "      <td>0.491109</td>\n",
       "      <td>0.510937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4  lower_ci  \\\n",
       "califorest  0.508045  0.522168  0.542909  0.466901  0.415518   0.47128   \n",
       "\n",
       "                mean  upper_ci  \n",
       "califorest  0.491109  0.510937  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auprc_scores = auprc_df.T\n",
    "auprc_scores['lower_ci'] = auprc_df.T.mean(axis=1) - 1.96*auprc_df.T.std(axis=1)/auprc_df.T.count(axis=1)\n",
    "auprc_scores['mean'] = auprc_df.T.mean(axis=1)\n",
    "auprc_scores['upper_ci'] = auprc_df.T.mean(axis=1) + 1.96*auprc_df.T.std(axis=1)/auprc_df.T.count(axis=1)\n",
    "#auc_scores.sort_values(by='mean', ascending=False)\n",
    "auprc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>mean</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>califorest</th>\n",
       "      <td>-0.32532</td>\n",
       "      <td>-0.328563</td>\n",
       "      <td>-0.337507</td>\n",
       "      <td>-0.33828</td>\n",
       "      <td>-0.359201</td>\n",
       "      <td>-0.342958</td>\n",
       "      <td>-0.337774</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2        3         4  lower_ci  \\\n",
       "califorest -0.32532 -0.328563 -0.337507 -0.33828 -0.359201 -0.342958   \n",
       "\n",
       "                mean  upper_ci  \n",
       "califorest -0.337774 -0.332591  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bss_scores = bss_df.T\n",
    "bss_scores['lower_ci'] = bss_df.T.mean(axis=1) - 1.96*bss_df.T.std(axis=1)/bss_df.T.count(axis=1)\n",
    "bss_scores['mean'] = bss_df.T.mean(axis=1)\n",
    "bss_scores['upper_ci'] = bss_df.T.mean(axis=1) + 1.96*bss_df.T.std(axis=1)/bss_df.T.count(axis=1)\n",
    "#auc_scores.sort_values(by='mean', ascending=False)\n",
    "bss_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "763944e8a0f0ced878785a0a4fba7a66755afcae9e9bfcbb46e371437d18a427"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
